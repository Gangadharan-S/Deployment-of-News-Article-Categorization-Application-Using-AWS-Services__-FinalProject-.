# -*- coding: utf-8 -*-
"""news_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qUemj_qC7JnNCTk2-FkJlh6A2e5hNqN
"""

!pip install -q streamlit pyngrok tensorflow pillow pandas

# Commented out IPython magic to ensure Python compatibility.
# 
# # ğŸ§  News Article Categorization using TinyBERT (Colab-ready)
# # ==================================================
# %%writefile app.py
# import streamlit as st
# import torch
# import datetime
# import pandas as pd
# import os
# from transformers import BertTokenizer, BertForSequenceClassification
# 
# st.set_page_config(page_title="ğŸ“° News Article Categorization", layout="centered")
# 
# @st.cache_resource
# def load_model_and_tokenizer():
#     model_path = "/content/drive/MyDrive/news/bert_tiny_news_classifier_final.pth"
#     model = BertForSequenceClassification.from_pretrained("prajjwal1/bert-tiny", num_labels=4)
#     model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))
#     model.eval()
#     tokenizer = BertTokenizer.from_pretrained("prajjwal1/bert-tiny")
#     return tokenizer, model
# 
# tokenizer, model = load_model_and_tokenizer()
# labels = ["World", "Sports", "Business", "Sci/Tech"]
# 
# def predict_category(text):
#     inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
#     with torch.no_grad():
#         outputs = model(**inputs)
#     logits = outputs.logits
#     predicted_class = logits.argmax().item()
#     confidence = torch.softmax(logits, dim=1)[0][predicted_class].item() * 100
#     return labels[predicted_class], confidence
# 
# # ---------------------- STORE DATA TO CSV ----------------------
# def store_data(name, time, input_text=None, predicted_category=None):
#     """Store all user interactions to a CSV file in Google Drive."""
#     csv_path = "/content/drive/MyDrive/news_classifier_logs.csv"
# 
#     new_data = pd.DataFrame([{
#         "name": name,
#         "interaction_time": time,
#         "input_text": input_text,
#         "predicted_category": predicted_category
#     }])
# 
#     if os.path.exists(csv_path):
#         existing = pd.read_csv(csv_path)
#         updated = pd.concat([existing, new_data], ignore_index=True)
#     else:
#         updated = new_data
# 
#     updated.to_csv(csv_path, index=False)
#     st.success(f"âœ… Data saved to CSV: {csv_path}")
# 
# # ---------------------- STREAMLIT APP UI ----------------------
# st.title("ğŸ§  News Article Categorization using TinyBERT")
# st.write("Paste any **news article**, and the model will predict its category!")
# 
# st.sidebar.header("âš™ï¸ Settings")
# confidence_threshold = st.sidebar.slider("Confidence Threshold (%)", 0, 100, 50, 5)
# 
# st.divider()
# 
# # ---------------------- SESSION STATE ----------------------
# if "name_entered" not in st.session_state:
#     st.session_state.name_entered = False
# if "name" not in st.session_state:
#     st.session_state.name = ""
# 
# # Step 1: Enter name
# if not st.session_state.name_entered:
#     name = st.text_input("ğŸ‘¤ Enter your name:")
#     if st.button("ğŸš€ Start"):
#         if name.strip() == "":
#             st.warning("Please enter your name before starting.")
#         else:
#             st.session_state.name = name
#             st.session_state.name_entered = True
#             st.rerun()
# else:
#     st.success(f"âœ… Welcome, {st.session_state.name}! You can now classify articles.")
#     st.divider()
# 
#     # Step 2: Enter article text
#     user_input = st.text_area("ğŸ“° Paste your news article here:")
# 
#     # Step 3: Categorize
#     if st.button("ğŸ” Categorize"):
#         if user_input.strip() == "":
#             st.warning("Please enter a news article.")
#         else:
#             with st.spinner("Analyzing article..."):
#                 category, confidence = predict_category(user_input)
#                 if confidence >= confidence_threshold:
#                     st.success(f"ğŸ¯ Predicted Category: **{category}**")
#                     st.write(f"ğŸ“Š Confidence: **{confidence:.2f}%**")
#                 else:
#                     st.warning(f"âš ï¸ Confidence ({confidence:.2f}%) is below threshold.")
# 
#                 # Save interaction to CSV in Google Drive
#                 store_data(st.session_state.name, datetime.datetime.now(), user_input, category)
# 
#     # Step 4: Back button
#     if st.button("ğŸ”™ Back"):
#         st.session_state.name_entered = False
#         st.session_state.name = ""
#         st.rerun()
#

from pyngrok import conf, ngrok

conf.get_default().auth_token = "2zSwv7MhadWyFUgXnQINzLgNLQk_6ALkEGghZTMkRNFwyDKNW"

# Step 2: Kill previous tunnels
ngrok.kill()

public_url = ngrok.connect("http://localhost:8501", proto="http")
print(f"ğŸŒ Your Streamlit app is live at: {public_url}")


# Step 4: Start the Streamlit app
!streamlit run app.py --server.port 8501 --server.enableCORS false